{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PVHf7_tpTm2"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install emoji\n",
        "!pip install wordsegment"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o-HeNcufT1n",
        "outputId": "fbe9dac7-c0e1-4b86-f479-b49525c82f17"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import wordsegment\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRK_oDn2fT1u"
      },
      "source": [
        "set_seed(530)\n",
        "train_df = pd.read_csv('train.csv')\n",
        "dev_df = pd.read_csv('dev.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "train_texts = list(train_df['tweet'].values)\n",
        "train_labels = list(train_df['class'].values)\n",
        "\n",
        "dev_texts = list(dev_df['tweet'].values)\n",
        "dev_labels = list(dev_df['class'].values)\n",
        "\n",
        "test_texts = list(test_df['tweet'].values)\n",
        "test_labels = list(test_df['class'].values)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ-3xYvKe_AV"
      },
      "source": [
        "def preprocess(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    # limit consecutive @user\n",
        "    tweet = re.sub(r\"(@user ){3,}\", \"@user @user @user \", tweet)\n",
        "    # replace \"url\" with \"html\" for embedding\n",
        "    tweet = tweet.replace(\"url\", \"html\")\n",
        "    # translate emoji into words\n",
        "    tweet = emoji.demojize(tweet)\n",
        "    # segment hashtag & emoji translations\n",
        "    tweet = \" \".join(wordsegment.segment(tweet))\n",
        "    return tweet"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Zz_Co2W96z",
        "outputId": "577adb86-a59b-497d-8d84-d284a40a12b2"
      },
      "source": [
        "%%time\n",
        "\n",
        "wordsegment.load()\n",
        "\n",
        "train_texts = list(train_df['tweet'].apply(lambda x: preprocess(x)).values)\n",
        "dev_texts = list(dev_df['tweet'].apply(lambda x: preprocess(x)).values)\n",
        "test_texts = list(test_df['tweet'].apply(lambda x: preprocess(x)).values)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39min 3s, sys: 13.9 s, total: 39min 17s\n",
            "Wall time: 39min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD0Kvp76fT1w"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va2iLEKZfT1w"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def load_data(train_texts, train_labels, dev_texts, dev_labels, test_texts, test_labels):\n",
        "    train_encodings = tokenizer(train_texts, padding=True)\n",
        "    dev_encodings = tokenizer(dev_texts, padding=True)\n",
        "    test_encodings = tokenizer(test_texts, padding=True)\n",
        "    \n",
        "    train_dataset = Dataset(train_encodings, train_labels)\n",
        "    dev_dataset = Dataset(dev_encodings, dev_labels)\n",
        "    test_dataset = Dataset(test_encodings, test_labels)\n",
        "    \n",
        "    return train_dataset, dev_dataset, test_dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpF1WLGZBDDv"
      },
      "source": [
        "train_dataset, dev_dataset, test_dataset = load_data(train_texts, train_labels, dev_texts, dev_labels, test_texts, test_labels)\n",
        "train_loader= DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
        "dev_loader= DataLoader(dev_dataset, shuffle=False, batch_size=64)\n",
        "test_loader= DataLoader(test_dataset, shuffle=False, batch_size=64)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRRnkBDCfT1v",
        "outputId": "9523fb20-e5cf-4b01-bfa3-e07b4677760a"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2)\n",
        "optim = AdamW(model.parameters(), lr=3e-5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Dz47p2fT1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b861982-4550-476d-f7f0-90e30010618b"
      },
      "source": [
        "%%time\n",
        "\n",
        "# training\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(5):\n",
        "    avg_loss = []\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels = labels, return_dict=True)\n",
        "        loss = outputs.loss\n",
        "        avg_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "    print(\"Epoch %d loss =\" %epoch, np.mean(avg_loss))\n",
        "    \n",
        "model_path = \"models\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 loss = 0.4946779360108197\n",
            "Epoch 1 loss = 0.38214835030509825\n",
            "Epoch 2 loss = 0.2765058110104525\n",
            "Epoch 3 loss = 0.1707656903461339\n",
            "Epoch 4 loss = 0.09959018328550824\n",
            "CPU times: user 19min 25s, sys: 14min 55s, total: 34min 21s\n",
            "Wall time: 34min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ztybpgwNuU6"
      },
      "source": [
        "# evaluation with development set\n",
        "model.eval()\n",
        "dev_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in dev_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs=model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        logits = outputs.logits\n",
        "        prob = torch.softmax(logits, dim=1).tolist()\n",
        "        pred = [p.index(max(p)) for p in prob]\n",
        "        dev_preds += pred"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPOp9QXsN5jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223f1d69-d8d7-47cc-a792-060c7a83a909"
      },
      "source": [
        "fscore = f1_score(dev_preds, dev_labels, average='macro')\n",
        "print(\"The development F1 score is:\", fscore)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The development F1 score is: 0.7460267957695059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MxuBG--fT1x"
      },
      "source": [
        "# evaluation with testing set\n",
        "model.eval()\n",
        "test_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs=model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        logits = outputs.logits\n",
        "        prob = torch.softmax(logits, dim=1).tolist()\n",
        "        pred = [p.index(max(p)) for p in prob]\n",
        "        test_preds += pred"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir5DvnU2fT1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce0e8e5-e9c4-4e4e-f7f3-5fa53efa2174"
      },
      "source": [
        "fscore = f1_score(test_preds, test_labels, average='macro')\n",
        "print(\"The training F1 score is:\", fscore)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training F1 score is: 0.7765610679418211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS9UTSslfT1x"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}